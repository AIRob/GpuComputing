{
 "metadata": {
  "name": "Reduce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Reduce\n",
      "\n",
      "The purpose of this code is to implement a canonical reduce algorithm on the GPU."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import numpy\n",
      "import pycuda.autoinit\n",
      "import pycuda.driver\n",
      "import pycuda.compiler\n",
      "\n",
      "class ReduceManager:\n",
      "    \n",
      "    source_module = pycuda.compiler.SourceModule \\\n",
      "    (\n",
      "    \"\"\"\n",
      "    __global__ void reduce_sum( float* d_scratchpad, int n, int num_threads )\n",
      "    {\n",
      "        int global_index_1d = ( blockIdx.x * blockDim.x ) + threadIdx.x;\n",
      " \n",
      "        int left_index  = global_index_1d;\n",
      "        int right_index = global_index_1d + num_threads;\n",
      "\n",
      "        if ( right_index < n )\n",
      "        {\n",
      "            d_scratchpad[ left_index ] = d_scratchpad[ left_index ] + d_scratchpad[ right_index ];\n",
      "        }\n",
      "    }\n",
      "\n",
      "    __global__ void reduce_product( float* d_scratchpad, int n, int num_threads )\n",
      "    {\n",
      "        int global_index_1d = ( blockIdx.x * blockDim.x ) + threadIdx.x;\n",
      " \n",
      "        int left_index  = global_index_1d;\n",
      "        int right_index = global_index_1d + num_threads;\n",
      "\n",
      "        if ( right_index < n )\n",
      "        {\n",
      "            d_scratchpad[ left_index ] = d_scratchpad[ left_index ] * d_scratchpad[ right_index ];\n",
      "        }\n",
      "    }\n",
      "\n",
      "    __global__ void reduce_min( float* d_scratchpad, int n, int num_threads )\n",
      "    {\n",
      "        int global_index_1d = ( blockIdx.x * blockDim.x ) + threadIdx.x;\n",
      " \n",
      "        int left_index  = global_index_1d;\n",
      "        int right_index = global_index_1d + num_threads;\n",
      "\n",
      "        if ( right_index < n )\n",
      "        {\n",
      "            d_scratchpad[ left_index ] = min( d_scratchpad[ left_index ], d_scratchpad[ right_index ] );\n",
      "        }\n",
      "    }\n",
      "\n",
      "    __global__ void reduce_max( float* d_scratchpad, int n, int num_threads )\n",
      "    {\n",
      "        int global_index_1d = ( blockIdx.x * blockDim.x ) + threadIdx.x;\n",
      " \n",
      "        int left_index  = global_index_1d;\n",
      "        int right_index = global_index_1d + num_threads;\n",
      "\n",
      "        if ( right_index < n )\n",
      "        {\n",
      "            d_scratchpad[ left_index ] = max( d_scratchpad[ left_index ], d_scratchpad[ right_index ] );\n",
      "        }\n",
      "    }    \n",
      "    \"\"\"\n",
      "    )\n",
      "\n",
      "    _reduce_sum_function     = source_module.get_function(\"reduce_sum\")\n",
      "    _reduce_product_function = source_module.get_function(\"reduce_product\")\n",
      "    _reduce_min_function     = source_module.get_function(\"reduce_min\")\n",
      "    _reduce_max_function     = source_module.get_function(\"reduce_max\")\n",
      "\n",
      "    _size_of_element_bytes           = 4\n",
      "    _block_size_num_elements         = 1024\n",
      "    _block_size_num_threads          = _block_size_num_elements / 2\n",
      "\n",
      "    _max_num_elements                = -1\n",
      "    _n                               = -1\n",
      "    _scratchpad_device               = -1\n",
      "\n",
      "    def __init__(self, max_num_elements):\n",
      "        \n",
      "        self._max_num_elements          = max_num_elements\n",
      "        self._num_bytes                 = self._max_num_elements * self._size_of_element_bytes\n",
      "        self._scratchpad_device         = pycuda.driver.mem_alloc(self._num_bytes)\n",
      "\n",
      "    def __copy_input_htod(self, input_data_host):\n",
      "\n",
      "        assert input_data_host.shape[0] <= self._max_num_elements\n",
      "        assert input_data_host.dtype    == numpy.float32\n",
      "\n",
      "        pycuda.driver.memcpy_htod(self._scratchpad_device, input_data_host)\n",
      "\n",
      "    def __copy_input_dtod(self, input_data_device, num_elements):\n",
      "\n",
      "        pycuda.driver.memcpy_dtod(self._scratchpad_device, input_data_device, int(num_elements * self._size_of_element_bytes))\n",
      "        \n",
      "    def __reduce(self, num_elements, reduce_function):\n",
      "\n",
      "        self._n = num_elements\n",
      "\n",
      "        num_sweep_passes    = int(math.ceil(math.log(num_elements,2)))\n",
      "        reduce_num_elements = self._n\n",
      "        \n",
      "        for d in range(num_sweep_passes):\n",
      "\n",
      "            reduce_num_threads    = int(math.ceil(float(reduce_num_elements) / float(2)))\n",
      "            \n",
      "            reduce_function_block = (self._block_size_num_threads,1,1)\n",
      "            num_blocks            = int(math.ceil(float(reduce_num_threads) / float(reduce_function_block[0])))\n",
      "            reduce_function_grid  = (num_blocks, 1)\n",
      "            \n",
      "            reduce_function(\n",
      "                self._scratchpad_device,\n",
      "                numpy.int32(reduce_num_elements),\n",
      "                numpy.int32(reduce_num_threads),                \n",
      "                block=reduce_function_block,\n",
      "                grid=reduce_function_grid)\n",
      "\n",
      "            reduce_num_elements = reduce_num_threads\n",
      "\n",
      "        tmp = numpy.zeros(1, dtype=numpy.float32)\n",
      "\n",
      "        pycuda.driver.memcpy_dtoh(tmp, self._scratchpad_device)\n",
      "\n",
      "        return tmp[0]\n",
      "\n",
      "    def reduce_sum_device(self, input_data_device, num_elements):\n",
      "\n",
      "        self.__copy_input_dtod(input_data_device, num_elements)\n",
      "        return self.__reduce(num_elements, self._reduce_sum_function)\n",
      "\n",
      "    def reduce_product_device(self, input_data_device, num_elements):\n",
      "\n",
      "        self.__copy_input_dtod(input_data_device, num_elements)\n",
      "        return self.__reduce(num_elements, self._reduce_product_function)\n",
      "\n",
      "    def reduce_min_device(self, input_data_device, num_elements):\n",
      "\n",
      "        self.__copy_input_dtod(input_data_device, num_elements)\n",
      "        return self.__reduce(num_elements, self._reduce_min_function)\n",
      "\n",
      "    def reduce_max_device(self, input_data_device, num_elements):\n",
      "\n",
      "        self.__copy_input_dtod(input_data_device, num_elements)\n",
      "        return self.__reduce(num_elements, self._reduce_max_function)\n",
      "\n",
      "    def reduce_sum_host(self, input_data_host):\n",
      "\n",
      "        num_elements = input_data_host.shape[0]\n",
      "        \n",
      "        self.__copy_input_htod(input_data_host)\n",
      "        return self.__reduce(num_elements, self._reduce_sum_function)\n",
      "\n",
      "    def reduce_product_host(self, input_data_host):\n",
      "\n",
      "        num_elements = input_data_host.shape[0]\n",
      "        \n",
      "        self.__copy_input_htod(input_data_host)\n",
      "        return self.__reduce(num_elements, self._reduce_product_function)\n",
      "\n",
      "    def reduce_min_host(self, input_data_host):\n",
      "\n",
      "        num_elements = input_data_host.shape[0]\n",
      "        \n",
      "        self.__copy_input_htod(input_data_host)\n",
      "        return self.__reduce(num_elements, self._reduce_min_function)\n",
      "\n",
      "    def reduce_max_host(self, input_data_host):\n",
      "\n",
      "        num_elements = input_data_host.shape[0]\n",
      "        \n",
      "        self.__copy_input_htod(input_data_host)\n",
      "        return self.__reduce(num_elements, self._reduce_max_function)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n          = 10000\n",
      "input_data = (numpy.random.rand(n)).astype(numpy.float32)\n",
      "\n",
      "reduce_manager = ReduceManager(n)\n",
      "\n",
      "print \"Difference between GPU and CPU sum reduce (should be less than 0.1): %f\" % abs( reduce_manager.reduce_sum_host(input_data) - numpy.sum(input_data) )\n",
      "print\n",
      "print \"%f\" % numpy.sum(input_data)\n",
      "print \"%f\" % reduce_manager.reduce_sum_host(input_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Difference between GPU and CPU sum reduce (should be less than 0.1): 0.004395\n",
        "\n",
        "5001.355957\n",
        "5001.351562\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n          = 20\n",
      "input_data = (numpy.random.rand(n) + 1.01).astype(numpy.float32)\n",
      "\n",
      "reduce_manager = ReduceManager(n)\n",
      "\n",
      "print \"Difference between GPU and CPU product reduce (should be less than 0.1): %f\" % abs( reduce_manager.reduce_product_host(input_data) - numpy.prod(input_data) )\n",
      "print\n",
      "print \"%f\" % numpy.prod(input_data)\n",
      "print \"%f\" % reduce_manager.reduce_product_host(input_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Difference between GPU and CPU product reduce (should be less than 0.1): 0.000061\n",
        "\n",
        "926.643677\n",
        "926.643616\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n          = 10000\n",
      "input_data = (numpy.random.rand(n)).astype(numpy.float32)\n",
      "\n",
      "reduce_manager = ReduceManager(n)\n",
      "\n",
      "print \"Difference between GPU and CPU min reduce (should be 0.0): %f\" % abs( reduce_manager.reduce_min_host(input_data) - numpy.min(input_data) )\n",
      "print\n",
      "print \"%f\" % numpy.min(input_data)\n",
      "print \"%f\" % reduce_manager.reduce_min_host(input_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Difference between GPU and CPU min reduce (should be 0.0): 0.000000\n",
        "\n",
        "0.000093\n",
        "0.000093\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n          = 10000\n",
      "input_data = (numpy.random.rand(n)).astype(numpy.float32)\n",
      "\n",
      "reduce_manager = ReduceManager(n)\n",
      "\n",
      "print \"Difference between GPU and CPU max reduce (should be 0.0): %f\" % abs( reduce_manager.reduce_max_host(input_data) - numpy.max(input_data) )\n",
      "print\n",
      "print \"%f\" % numpy.max(input_data)\n",
      "print \"%f\" % reduce_manager.reduce_max_host(input_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Difference between GPU and CPU max reduce (should be 0.0): 0.000000\n",
        "\n",
        "0.999933\n",
        "0.999933\n"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}